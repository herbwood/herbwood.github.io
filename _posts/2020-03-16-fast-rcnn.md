---
layout: post
title:  "[DL] Fast R-CNN 논문 리뷰"
subtitle:   "fast r-cnn"
categories: study
tags: dl
comments: true
use_math : true
---

Fast R-CNN은 R-CNN에 이은 two-stage detection 계열의 모델입니다. 하지만 네트워크의 구조 는 질적인 측면에서 크게 달라집니다. 이를 통해 Fast R-CNN은 성능 및 속도 측면에서 기존의 알고리즘을 크게 웃도는 모습을 보입니다. Fast R-CNN 논문을 통해 개선됨 점들을 자세히 살펴보도록 하겠습니다. 

### What's the problem?

- R-CNN과 SPPNet은 네트워크가 구조적으로 **multi stage pipeline**입니다. 입력 이미지는 CNN을 거쳐 SVM을 통해 분류되고, region proposal의 좌표는 bounding box regressor에 전달됩니다. 문제는 이러한 여러 단계를 거치는 방식이 속도와 성능을 갉아먹는다는 것입니다. 

- SPPNet은 SPP layer를 통해 속도를 크게 증가시켰지만 여전히 multi stage pipeline 모델이며, 네트워크의 연산(convolution)을 공유하지 않아 속도와 성능의 한계가 존재합니다. 앞선 두 모델은 fc layer에 대해서만 fine tuning을 진행했습니다. 이는 conv layer의 가중치값이 고정돼 **네트워크를 update하는 것이 불가능**하며, 이를 통해 정확도에 제한이 생깁니다. 

Fast R-CNN은 위와 같은 두 문제를 인지하고 다양한 방법을 통해 해결합니다. 이에 대해 자세히 살펴보도록 하겠습니다. 

### Improvements

#### 1) RoI(Region of Interest) Pooling

<p align='center'><img src='https://miro.medium.com/max/1400/1*aB4gy6i8Zc3BasYaQGDVtg.png'></p><p align='center'>[그림 1] RoI Pooling </p>

**RoI pooling layer**는 feature map 상의 특정 영역에 대해 일정한 개수의 bin으로 영역을 나눈 뒤, 각 bin에 대해 max pooling하여 고정된 길이의 feature vector를 가져는 layer입니다. region proposal의 크기가 (H x W)라고 할 때, 지정한 bin의 크기를 (h x w)로 하면 H/h, W/w 크기의 window를 만들어 max pooling을 적용합니다. SPP layer를 single level로만 적용한 특수한 경우라고 논문에서 언급합니다. 이를 통해 SPPNet과 마찬가지로 학습 및 inference 속도를 크게 감소하였습니다. 


#### 2) Multi-task loss function

Fast R-CNN 모델은 classification과 bounding box regression을 동시에 학습시킬 수 있는 **multi-task loss function**을 도입했습니다. 우항의 첫 번째 수식은 **classification loss**입니다. 로그 함수를 적용하여 class에 대한 예측 정도를 나타냈습니다. 두 번째 수식은 **bounding box regression loss function**입니다. indicator function을 통해 background일 경우 계산하지 않도록 했으며, balancing hyperparamter를 곱해줌으로써 두 loss function의 영향력을 조절하는 것이 가능합니다. 
<p align='center'><img src='https://ifh.cc/g/zMquW8.png'></p><p align='center'>[그림 2] Multi-task loss </p>


Multi-task loss function을 통해 모델이 **single stage**로 Object detection을 하는 것이 가능해졌습니다. 기존에 SVM을 통한 분류와 Bounding box Regression이 따로 진행되는 것과 달리 Fast R-CNN은 통합된 loss function을 통해 학습이 **동시에** 진행됩니다. 이를 통해 학습 및 inference 시간이 크게 감소하게 됩니다. 

#### 3) Hierarchial Sampling

<p align='center'><img src='https://ifh.cc/g/XLWT63.jpg'></p><p align='center'>[그림 3] Hierarchial Sampling </p>

SPPNet이나 R-CNN은 서로 다른 이미지를 학습으로 사용할 경우 역전파를 통해 네트워크를 학습시키는 것은 매우 비효율적입니다. 이러한 문제를 해결하기 위해 Fast R-CNN은 SGD(Stochastic Gradient Descent)가 처음 n개의 이미지를 **sample**하고 각 이미지별로 (r/n)개의 region proposal을 sample합니다. 이 기법을 통해 forward propagation, backpropagation 시 같은 메모리오 연산을 공유함으로서 학습을 효율적으로 하는 것이 가능해집니다. 이와 같이 계층적으로 sampling하는 기법을 **Heirarchial Sampling**이라고 합니다. 예를 들어 이미지 두 장에 region propsal이 128개인 경우(n=2, r=128), 기존의 방식보다 64배 빠릅니다. Fast R-CNN은 계층적 sampling을 통해 64개의 region proposal이 한 묶음으로 같이 학습되는 반면, 기존의 방식은 region of proposal이 개별적으로 학습되기 때문입니다. 

### Model Architecture

전체적인 학습 과정은 기존의 Object detection 알고리즘과 유사합니다. 다만 SVN이 fc layer의 softmax function으로 대체되고 multi-task loss function 사용, hierarchial sampling을 통한 연산 공유 등을 통해 **one-stage training**이 가능해졌습니다. 이를 통해 성능이 향상되고 학습 및 inference 속도가 크게 감소했습니다. 

<p align="center"><img src="https://ifh.cc/g/efsLeE.jpg" width="500"><p>
<p align="center">[그림 4]Fast R-CNN Model Architecture<p>

1) 원본 이미지와 region proposal을 CNN의 input으로 받습니다.

2) 원본 이미지는 CNN을 거치고 region propsal은 RoI(Resion of Interest) pooling layer를 거쳐 feature map으로부터 고정된 vecto가 추출됩니다.  

3) 각 feature vector는 fc layer를 거쳐 출력 결과 2개를 냅니다. 하나는 k개의 객체의 범주와 배경에 대한 softmax 확률, 그리고 객체가 있는 bounding box 좌표값 실수 4개를 반환합니다.  

### Training Details  

#### Fine tuning   

논문의 후반부에는 모델에 대한 다양한 실험 결과를 언급합니다. 그 중 가장 인상깊었던 부분은 **Fine Tuning**에 대한 부분이었습니다. SPPNet이 conv layer는 freeze시키고 fc layer만 fine tuning한 것에 비해 Fast R-CNN은 con layer까지 전부 fine tuning했습니다.
<p align="center"><img src="https://ifh.cc/g/v9sKia.jpg" width="400"><p>
<p align="center">[그림 5]Fast R-CNN 학습 과정<p>

 이를 통해 성능 면에서 큰 차이를 확인할 수 있었고, conv layer를 하지 않았을 때보다 5.5%나 높은(61.4%->66.9%) mAP값을 얻을 수 있었다고 합니다. 다만 conv1, conv2까지 전부 fine tuning을 했을 시 소폭의 성능 하락이 있어 conv3부터 fine tuning을 적용했다고 합니다. 
 
 
#### Truncated SVD  

<p align="center"><img src="https://ifh.cc/g/qosSNL.png" width="400"><p>
<p align="center">[그림 6]Truncated SVD<p>
논문에서는 모델의 학습 속도를 낮추기 위해 **Truncated SVD**를 활용하여 파라미터의 수를 줄입니다. 논문의 저자는 fc layer가 detection 시 많은 시간을 잡아먹는다는 것을 확인했습니다. 이를 해결하기 위해 Truncated SVD를 활용하여 UV개의 파라미터를 t(U+V)개로 줄였습니다. Truncated SVD는 행렬의 대각원소 가운데 상위 t개만 골라낸 형태로, 데이터를 압축했지만 원본 행렬에 근사할 수 있는 방법입니다. 이를 통해 detection 시간을 30%이상 감소시켰지만 성능은 오직 0.3%만 하락했다고 합니다.   

### Performance

<p align="center"><img src="https://ifh.cc/g/QfU9HC.jpg" width="500"><p>
<p align="center"><img src="https://ifh.cc/g/6RA3bI.png" width="300"><p>
<p align="center">[그림 6] Fast R-CNN Performance <p>

Fast R-CNN은 VOC2012, VOC2007 데이터셋에서 기존 모델보다 좋은 성능을 보입니다. Fast R-CNN은 VOC2007 데이터셋에서 70%라는 mAP 수치를 보입니다. 또한 학습 속도 면에서 SPPNet보다 18배 이상 빠른 결과를 보였습니다.  

### Conclusion  

Fast R-CNN은 "빠른"이라는 수식어가 붙는 만큼 속도 측면에서 좋은 모습을 보여주었지만 저는 개인적으로 CNN을 학습에 본격적으로 사용했다는 점이 좀 더 의의가 있는 것 같습니다. 네트워크를 통해 활용함으로써 역전파가 가능해지고 학습 속도가 빨라지면서 딥러닝을 적용하는 이유를 제대로 보여줬다는 생각이 들었습니다.  

### Reference  
  
[Fast R-CNN 논문](https://arxiv.org/pdf/1504.08083.pdf)   
[컴퓨터 비전 분야의 갓 블로그 라온피플](https://m.blog.naver.com/PostView.nhn?blogId=laonple&logNo=220776743537&proxyReferer=https:%2F%2Fwww.google.com%2F)  
[Fast R-CNN에 대해 잘 설명한 블로그](https://woosikyang.github.io/fast-rcnn.html)  
[truncated SVD에 대해 잘 설명한 블로그](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/06/pcasvdlsa/)  
