---
layout: post
title:  "[DL] RCNN 논문 리뷰"
subtitle:   "rcnn"
categories: study
tags: dl
comments: true
use_math : true
---

과거 Object detection 작업을 위해 이미지의 feature를 통계학적으로 분석하여 객체를 탐지하는 SIFT, HOG 등의 방식을 사용했습니다. 하지만 하드웨어 성능의 향상과 CNN 모델의 발견으로 Object detection 분야에 딥러닝을 적용할 수 있게 되었습니다. 이번 포스팅에서는 Object detection에 딥러닝을 적용하여 유의미한 성과를 보인 RCNN 모델에 대해 살펴보도록 하겠습니다. 

### Problems to solve

Object detection 분야에 딥러닝을 적용하기 위해서는 해결해야 할 두 가지 과제가 있습니다. 먼저 객체의 위치를 찾는 localizing을 효과적으로 수행해야 하며, 두 번째로 딥러닝 모델을 학습시킬 수 있는 충분한 학습 데이터를 확보해야만 합니다.

-  RCNN 논문의 저자는 localizing 문제를 해결하기 위해 객체가 있을법한 영역을 선정하여 추출하는 **Region Proposal** 방법을 제시합니다. 객체의 예상 위치를 일부 추출하기 때문에 고정된 크기의 window를 원본 이미지에 위치를 옮겨가며 crop하는 기존의 방식인 sliding window에 비해 상대적으로 효율적이라고 할 수 있습니다.(RCNN의 R은 "Region Propsal"에서 따온 것입니다)

- Object detection 분야에 딥러닝을 적용하기 위해서 적절한 양의 학습 데이터가 필요하지만 당시 학습 데이터가 충분하지 않다는 문제가 있었습니다. 논문의 저자는 **pre-trained**된 기존의 CNN 모델을 불러와 소량의 데이터를 **fine tuning**을 통해 학습시키는 방법을 통해 이같은 문제를 해결합니다.

### Model Architecture

RCNN 모델의 학습은 다음과 같은 과정에 따라 진행됩니다.

![rcnn1](https://i.imgur.com/mfvzydg.png)
<p align='center'>[그림 1] RCNN 학습 과정 </p> 

1) **Extract region proposals**  
<p align='center'><img src="https://i.imgur.com/DPEJcwI.png" width="300" height="200"></p>

<p align='center'>[그림 2] Selective search </p>

우선 이미지 하나에 대해서 객체가 있을 법한 후보 영역(region proposal)을 2000개 정도 선택합니다. 후보 영역은 이미지의 픽셀 간의 유사도를 통해 grouping하는 **selective search** 방법을 통해 추출합니다. 논문에서는 다수의 이미지에 대해 region proposal을 진행한 결과 이미지 한 장당 평균 2403개의 후보 영역을 얻었다고 합니다.  

2) **Compute CNN features**

<p align='center'><img src="https://i.imgur.com/HV29CQH.png" width="400" height="300"></p>
<p align='center'>[그림 3] RCNN 학습 과정 </p>

- 그 다음으로 CNN 모델에 후보 영역의 feature를 추출하기 위해 각 region을 동일한 크기로 warp 시켜줍니다. 이 때 추천된 영역의 크기와 상관없이 모두 227x227 크기로 **warp**시켜줍니다. 이 때 후보 영역에 16 pixel만큼 크기를 확대하고 warp했을 시 가장 좋은 성능을 보였다고 합니다. 

- 그 다음으로 5개의 conv layer와 fully connected layer로 구성된 네트워크를 거쳐 각 영역에 대해서 4096차원의 feature vector를 추출합니다. 이 때 feature 추출을 위해 pre-trained된 VGG 모델을 사용하였으며, 예측하는 범주의 수에 맞게 fine tuning 작업을 진행합니다.

3) **classify regions by SVM**

마지막으로 CNN을 통해 나온 feature vector를 활용하여 **SVM(Support Vector machine)**을 통해 2천여개의 후보 영역에 대한 범주를 분류하고 **Non-max Suppression**를 적용시켜 최적의 bounding box를 탐색합니다. 이 과정에서 객체의 위치에 대한 bounding box 좌표값을 학습시키는 **Bounding box Regression** 또한 동시에 진행됩니다.  


### Why SVM?

- 여기서 흥미로운 점은 RCNN을 설계할 당시 CNN 네트워크 마지막 layer에 fully connected layer를 추가하지 않고 SVM을 통해 범주를 분류했다는 점입니다. 사실 CNN 네트워크 마지막 layer에 fully connected layer를 추가해 softmax 함수를 적용하는 것이 합리적으로 보입니다. 

<p align='center'>![positive, negative](https://ifh.cc/g/SvToZV.png)</p>
<p align='center'>[그림 4] Fine tuning과 SVM의 분류 기준 </p>

- 논문의 저자는 이에 대한 대답에 앞서 CNN 네트워크와 SVM이 후보 영역에 대해 서로 다른 기준을 적용한다는 점을 언급합니다. CNN 모델 같은 경우 fine tuning 시 후보 영역의 IoU가 0.5 이상이면 정답을 맞춘 것으로(positive) 간주하고 그 밖의 경우 오답(negative)으로 분류하는 반면, SVM은 후보 영역이 ground truth인 경우에만 positive로, IoU가 0.3 이하인 경우를 negative로 간주합니다. 

- 두 모델의 분류 기준이 다른 이유는 fine tuning 시 학습 데이터의 수가 적다는 점에 있습니다. SVM처럼 ground truth만을 positive로 간주하면 균형잡히고 적절한 양의 학습 데이터를 확보하기 힘들기 때문에 IoU를 기준으로 positive에 대한 다소 완화된 기준을 확립한 것입니다. 

- 하지만 이러한 완화된 분류 기준을 그대로 적용한 경우 객체의 위치를 정확하지 찾지 못한다는 문제가 발생했습니다. 이로 인해 CNN 네트워크 마지막에 fully connected layer를 추가해 softmax 함수를 적용했을 경우 mAP 값이 크게 하락했다고 합니다. '

- 즉, fine tuning 시에는 충분한 학습 데이터를 확보하기 위해 다소 완화된 분류 기준을 적용하고, 이로 인해 발생할 수 있는 localizing 성능 하락을 SVM을 통해 극복하고자 한 것입니다. 

### Bounding box Regression

논문의 저자는 localizing 성능을 높히기 위해 **Bounding box Regression**이라는 방법을 제시합니다. 

![bb](https://ifh.cc/g/IsxZdV.jpg)
<p align='center'>[그림 5] Bounding box Regression </p>

Bounding box Regression은 객체의 예상 좌표값을 ground truth 좌표값과 비교하고 loss function을 통해 학습시키는 방식입니다. 위의 그림에서 p는 region proposal을 통해 얻은 후보 영역, g는 ground truth 좌표값, t는 loss function을 통해 optimize하고자 하는 목표값입니다. 논문에서는 적절한 정규화 효과를 위해 regularization term을 추가하였으며, IoU가 특정 값 이상한 경우에만 regression을 적용하였습니다. 

### Non-max Suppression

**None-max Suppression**은 동일한 객체에 대해 여러 개의 bounding box가 생성되는 것을 방지하기 위한 방법입니다. 

![non-max suppression](https://lilianweng.github.io/lil-log/assets/images/non-max-suppression.png)
<p align='center'>[그림 6] Non-max Suppression </p>

Non-max Suppression은 먼저 confidence socre별로 bounding box를 나열한 뒤 기준치 이하의 confidence score를 가진 box부터 제거합니다. 그 다음 confidence score가 높은 box와 IoU가 높은 box를 제거합니다. confidence score가 높은 box와 IoU가 높다는 것은 객체의 위치에 대한 확신은 적으나 확신이 높은 box와 겹치는 위치에 있다는 것을 의미하므로 제거 대상이 됩니다. 그리고 위의 과정을 반복해주면 이전에 비해 불필요한 bounding box가 줄어든 것을 확인할 수 있습니다. 

### Performance
![performance](https://ifh.cc/g/nWY5rI.jpg)
<p align='center'>[그림 7]  Detection average precision (%) on VOC 2010 test </p>

RCNN의 Object detection 성능은 SIFT, HOG, DPM 등 기존의 방식보다 월등히 좋은 모습을 보였습니다. 실제로 위의 20개의 범주에 대해 상당히 높은 수준의 mAP값을 보이고 있습니다. 또한 딥러닝 네트워크의 파라미터는 예측하고자 하는 범주와 상관없이 공유되기 때문에 네트워크의 표현력이 향상된다는 장점도 있습니다. 

### Conclusion

지금까지 RCNN 모델에 대해 살펴보았습니다. 논문을 읽어보니 Non-max Suppression과 같은 상당히 생소한 개념들이 구체적인 설명 없이 제시되어 있어 세부적인 과정을 이해하는데 어려움이 있었습니다. 사실 모델의 구조나 학습 과정은 상대적으로 단순한 편이지만, 앞으로 등장할 RCNN 계열의 모델들을 보다 깊이있게 이해하기 위해 꼭 짚고 넘어가야한다고 생각했습니다. 다음에는 이후 RCNN 계열은 아니지만 Fast RCNN 설계에 큰 영향을 끼친 SPPNet에 대한 포스팅을 하도록 하겠습니다. 


### Reference

[RCNN 논문](https://arxiv.org/pdf/1311.2524.pdf)  
[RCNN 계열 모델에 대해 설명한 블로그(매우 유용!)](https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html)  
[RCNN에 대해 설명한 유튜브 채널](https://www.youtube.com/watch?v=W0U2mf9pf8o&t=178s)  

