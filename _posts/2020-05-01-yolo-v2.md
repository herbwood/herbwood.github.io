---
layout: post
title:  "[DL] YOLO v2 논문 리뷰 "
subtitle:   "yolo v2"
categories: study
tags: dl
comments: true
use_math : true
---

이번 포스팅에서는 YOLO의 두 번째 버전인 YOLO9000에 대해 살펴보도록 하겠습니다. 이번 논문은 개인적으로 상당히 읽기 쉽게 구성되었다고 생각합니다. 논문의 제목은 **YOLO9000:Better, Faster, Stronger**으로 이전 버전에 비해 개선한 점을 Better, Faster, Stronger이라는 세 가지 측면에서 살펴본다는 점이 흥미로웠습니다(내용은 어려웠습니다ㅠ). 이전 버전에 비해 성능이 크게 향상한YOLO9000의 개선점들에 대해 살펴보겠습니다. 

## What's the Problem?

-   YOLO v1은 Faster R-CNN과 비교했을 때 **localization error**, 즉 객체의 위치를 잘못 찾는 에러를 자주 범합니다.
-   또한 다른 region proposal based model에 비해 recall 지수(실제 객체인 사물을 객체라고 인식한 비율)가 상대적으로 낮습니다.

## Improvements

앞서 언급한 논문의 구성에 맞게 Better, Faster, Stronger라는 세 가지 측면에서 기존 모델에 대한 개선점을 살펴보도록 하겠습니다. 

### Better

간혹 딥러닝에서는 모델의 성능을 끌어올리기 위해 네트워크를 더 깊게 혹은 더 넓게 설계합니다. 하지만 논문의 저자는 빠르고 정확도가 높은 객체 검출 모델을 원하기 때문에 **네트워크의 복잡도를 늘리는 대신에 네트워크를 간소하게 만들고 representation을 더 쉽게 배울 수 있도록 만들었습니다.**

#### 1) Batch Normalization

- **Batch Normalization**을 적용하여 학습 속도를 향상시키며 정규화(regularization) 효과를 더해줍니다.

- YOLO9000에서는 Batch Normalization을 모든 conv layer마다 추가하여 mAP가 2% 정도 상승했습니다. 

#### 2) High Resolution Classifier

- YOLO v1에서는 이미지의 크기를 448x448 크기로 resize 해줍니다. 이 때 원래 학습시켰던 pretrained된 모델은 모두 224x224 정도의 작은 이미지 분류에 적응했기 때문에 크기가 큰 이미지에 대해서는 낮은 성능을 보입니다.

- 이러한 문제를 해결하기 위해서 새로운 모델을 448x448 크기의 이미지를  분류 모델로 학습시킵니다. 이 때 사용되는 분류 모델의 이름은 **darknet-19**입니다. YOLO9000의 논문의 저자들이 자체적으로 설계한 모델입니다. 10epochs, ImageNet 데이터셋을 사용하여 학습시켜 고해상도 이미지에 대한 학습을 진행하였습니다. 

- 이를 통해 4% 정도의 mAP 성능 향상했습니다. 
 
#### 3) Convolutionl With Anchor Boxes

- 먼저 **pooling layer를 제거**하여 네트워크의 출력단이 더 큰 크기를 가지도록 했습니다. 기존 YOLO v1의 경우 최종 출력단이 7x7 크기로, 상당히 낮은 해상도로 학습을 진행했기 때문입니다.
    
<p align="center"><img src="https://www.maskaravivek.com/post/yolov2/featured.png"></img></p>
<p align="center">[그림 1] YOLO v2  model architecture</p>

- 이미지 크기를 448x448이 아니라 **416x416**으로 바꿔 feature map의 크기가 홀수로 만들었습니다. 대체로 큰 객체일 경우 이미지의 중앙을 차지하는 경우가 많고, feature map의 크기가 홀수이기 때문에 정중앙의 cell에 대해서 bounding box를 예측하는 것이 가능하기 때문입니다.

- 마지막으로 각 cell마다 **anchor**를 사용한다. anchor를 사용하면 예측하는 bounding box의 수가 98개에서 1000개 이상으로 크게 늘기 때문에 정확도는 상대적으로 떨어집니다. anchor를 적용할 경우 69.2% mAP, recall은 88%인 반면, 미적용 시의 경우 mAP 69.5%, recall은 81%의 수치를 보였습니다. 즉 약간의 정확도 하락으로 높은 recall 값을 얻게 되어 localization error 문제를 어느 정도 해결할 수 있습니다. 

#### 4) Dimension Clusters

- Faster R-CNN은 사전에 anchor box의 scale과 aspect ratio를 사전에 미리 정해두어(prior hand pick) 9개의 anchor box를 사용했습니다. 하지만 모델이 스스로 최적의 anchor box 크기를 정하도록 하기 위해 ground truth box를 기반으로 **k-means clustering**을 사용했습니다.

<p align="center"><img src="https://mblogthumb-phinf.pstatic.net/MjAxNzA1MjJfMTA4/MDAxNDk1NDI4MDA1Mzg2.yXI55eFQL5TNbb0ifhf1pzeHOHXxXJDjGXOHDtN6R4Ig.0BnuYZzRLQ6_o6xDPRr774J4a1GoS8rdGMRnzDpPMuIg.PNG.sogangori/kmeansError.PNG?type=w2"></img></p>
<p align="center">[그림 2] IOU distance metric</p>

- 일반적인 k-means clustering의 경우, 유클리디안 거리를 기준으로 군집을 분류합니다. 하지만 이같은 방식을 사용할 경우 box가 겹치는 여부와 상관없이 중심점의 위치에 따라 군집이 정해지는 문제가 발생합니다. 논문의 저자는 이를 해결하기 위해 **IOU distance metric**을 통해 군집을 결정하는 방식을 사용했습니다.  

<p align="center"><img src="https://mblogthumb-phinf.pstatic.net/MjAxNzA1MjJfMjg5/MDAxNDk1NDE3NDQwNjA3.kpb5tcPYGbh2j1UZObIP1xlzkxqFuIXkZfcuNVRKjGgg.Rg8YvBlp3uhR31ytsY2YYBt-ED_zsx2oIZvKxvqPr-kg.PNG.sogangori/figure2.PNG?type=w2"></img></p>
<p align="center">[그림 3] Cluster 수와 Avg IOU 사이의 상관관계 </p>

- cluster의 수 k를 늘릴 수록 평균 IOU가 커지는 효과가 있으나 모델의 복잡도가 상승하게 됩니다. 논문의 저자는 둘 사이의 균형을 맞추기 위해 **k=5**로 지정하였습니다. 

- clustering을 통해 선택한 default box 5개의 평균 IOU 값이 anchor box 9개를 사용하여 학습했을 때보다 0.1 정도 높은 결과를 보였습니다. 

#### 5) Direct location prediction

- anchor box를 YOLO에 적용할 경우 생기는 문제점은 box의 중심점 좌표인 x,y 를 예측하는 데서 **모델이 불안정**하다는 것입니다. 초기의 중심 좌표들이 잘못 설정되면 이미지의 아무 점에서 마무리될 수 있다. 또한 random으로 지정하게 되면 모델은 안정되기까지 오랜 시간이 걸린다.

- 논문의 저자는 이를 해결하기 위해 offset을 예측하는 것이 아니라 grid cell과 관련된 위치 좌표를 예측하는 접근법을 사용합니다. 

<p align="center"><img src="https://user-images.githubusercontent.com/24144491/48917030-2071d100-eec8-11e8-8f53-a078c4974e7c.JPG"></img></p>
<p align="center">[그림 4] Bounding boxes with dimension priors and location </p>

- 중심좌표는 **시그모이드를 통해서 0으로 initialize**하면 너비과 높이 역시 0으로 초기화 했을때 prior, anchor box의 값들에서 시작될 수 있게 됩니다. 

- 이를 통해 5%의 성능을 향상시켰습니다. 

#### 6) Fine-Grained Features

- YOLO v2는 13x13 feature map에서 객체 검출을 예측합니다. 이 정도 크기는 큰 객체를 검출하기에 충분하지만 작은 객체를 검출하지 못할 수 있다. 

- 따라서 26x26 layer 에서 그다음 conv layer를 적용하지 않고 26x26x512의 특징맵을 13x13x(512x4)로 변환한다음(26x26에서 중심을 기준으로 2x2로 나눈 네 조각을 concatenate) detection을 위한 output으로 이어줍니다.

-  여기서 1%의 성능향상이 있습니다. 

#### 7) Multi-Scale Training

<p align="center"><img src="https://imgs.developpaper.com/imgs/1652092922-5c21dd797a903_articlex.png"></img></p>
<p align="center">[그림 5] Multi-scale training </p>

- YOLO v2는 SSD 모델처럼 다양한 image scale에 대한 학습을 진행합니다. 논문에서는 320, 320+32, 320+32*2, ..., 320+32*9 크기의 이미지를 학습시킵니다. YOLO가 원래 이미지 크기의 1/32 크기를 줄인 feature map을 추출하기 때문에 이와 같은 크기로 설정했다고 합니다. 10 batch마다 input shape을 변경시켜 학습시킵니다.

- 기본적으로 mAP값이 크게 상승하였고 resolution을 높힐수록 mAP값이 더 높아졌습니다. 

### Faster

논문의 저자는 로보틱스나 자율 주행차에서 사용될 수 있을 정도로 빠른 성능을 보이는 Object detection 모델을 설계하고자 했습니다. 이를 위해 가장 먼저 했던 작업은 baseline model로 사용되는 VGG 네트워크로부터 벗어나는 것이었습니다. 

#### 1) Darknet-19

-  VGG-16 모델은 성능은 준수하지만 필요 이상으로 많은 파라미터를 가지고 있다는 단점이 있습니다. 

<p align="center"><img src="https://user-images.githubusercontent.com/37808065/38984279-37328b2c-4401-11e8-8e8e-30edcb94cccd.png"></img></p>
<p align="center">[그림 5] Multi-scale training </p>

- 논문의 저자는 학습을 위해 커스텀한 CNN 모델인 **Darknet-19**를 설계했습니다. Darknet은 accuracy는 88%를 보이지만 파라미터 수는 5억 개 정도로 크게 줄였습니다. 

#### 2) Training for classification

- 분류 학습을 위한 상세 내용을 설명합니다. 

- epochs=160, learning rate=0.1, weight decay = 0.0005, mementum = 0.9

#### 3) Training for detection

- 객체 탐지 학습을 위한 상세 내용을 설명합니다. 

- 5개의 bounding box는 5개의 좌표(confidence score, bounding box offsets)와 20개의 class score를 예측합니다. 각 grid cell에서는 총 5 x (5 + 20) = 125개의 예측값을 가집니다. 

- data augmentation을 위해 random crops, color shifting을 사용했습니다. 

### Stronger

- 논문의 저자는 image classifcation의 범주는 수 천이 넘는 반면, object detection의 범주는 수 십개밖에 되지 않는 점을 극복하는 방안을 제시합니다. 

- 바로 detection 데이터셋과 classification 데이터셋을 섞어 학습하는 방식입니다. detection 데이터셋이 입력으로 들어오면 YOLO v2 loss function을 통해 학습시키며, classification 데이터셋이 입력으로 들어오면 classifcation loss function을 통해 학습시킵니다. 

- 이러한 방식으로 모델을 학습시킬 시 주의할 점은 노포크 테리어, 요크셔 테리어, 버들링턴 테리어는 모두 "개"라는 범주에 속하는 종들로 "개"라는 범주와 완전히 별도의 범주가 아니라는 것입니다. 이러한 범주 관계를 상호 배타적이지 않게 만들기 위해 **multi-label 모델**을 사용합니다. 

#### 1) Hierarchial classification

- ImageNet label은 **WordNet**이라는 언어 데이터베이스 구조 개념을 기반으로 작성되었습니다. WordNet에서 노포크 테리어와 요크셔 테리어는 공통적으로 "테리어", "사냥개", "개"라는 범주에 속합니다. 
"노포크 테리어"와 "개"를 상호 배타적이지 않게 label을 붙이기 위한 작업에 매우 적절하다고 할 수 있습니다. 
전체 WordNet을 사용하는 대신에 ImageNet label을 기반으로 계층 트리를 구성합니다. 

- 계층 트리를 구성하기 위해 WordNet 기반으로 label 수가 공통 범주에 속하는 수에 따라 label을 늘려갔습니다. 이를 통해 1000개에 해당하던 범주가 1369개까지 크게 늘어났습니다. 

<p align="center"><img src="https://ifh.cc/g/BuLL0z.png"></img></p>
<p align="center">[그림 6] Label prediction by using Conditional Probability  </p>

- 계층 트리를 사용할 경우 주어진 label과 각 하의어의 확률에 대하여 모든 노드에서 조건부 확률을 구합니다. 가령 이미지가 "노포크 테리어"인지 계산하기 위해서는 다음과 같이 계층 트리의 루트에서 특정 노드까지의 경로에 대한 조건부 확률을 모두 곱해줍니다. 

<p align="center"><img src="https://mblogthumb-phinf.pstatic.net/MjAxNzA1MjNfMTYy/MDAxNDk1NDk5ODIzNTU3.equpW9sIfxhTHF9B5qIRZaP-l1ZmuenBpfwe_hkiR50g.uC7UlEvWnkoIxF4_7hz4CfjgToyjwEcxfm4ICtxFKXMg.PNG.sogangori/figure5.PNG?type=w2"></img></p>
<p align="center">[그림 7] Prediction on ImageNet vs WordTree </p>

- 이를 통해 위와 같이 입력 이미지가 어떤 구체적인 범주에 속하는 것이 아닌 어떠한 상위 범주에 속하는지에 대한 softmax 함수를 적용하는 것이 가능해집니다. 
- 
#### 2) Dataset combination with Word Tree

<p align="center"><img src="https://mblogthumb-phinf.pstatic.net/MjAxNzA1MjNfMTYy/MDAxNDk1NTAyNTgxMjQx.zZ2tZNGuXkqG_Jtzb66r8i6_cXc_1og2IH-7zvu1l4Qg.9_7JW4Bg3to4qHFI7P6RVFCo4S98a3hj9YCgL2kd7RIg.PNG.sogangori/tree-word.PNG?type=w2"></img></p>
<p align="center">[그림 8] Word Tree</p>

- ImageNet 데이터셋과 COCO 데이터셋을 활용하여 위와 같은 WordTree를 만들었습니다. 

#### 3) Joint classification and detection

- 위와 같은 WordTree는 9418개의 label을 가집니다. 이러한 데이터셋을 활용하여 YOLO9000(**왜 v2가 아닌 9000이 붙는지 이유를 알게 되었습니다....**)

- detection 데이터셋이 입력으로 들어오면 YOLO v2 loss function을 사용해 역전파를 진행합니다. 하지만 classification 데이터셋이 입력으로 들어올 경우, 해당 label과 상위 범주에 대해서만 역전파를 진행합니다. 


## Conclusion

YOLO v2는 기존 객체 탐지 모델의 장점들을 포함시켜 모델 아키텍쳐에 변화를 주었습니다. 하지만 개인적으로 흥미로운 점은 딥러닝 모델 설계를 위해 k-means clustering과 같은 머신러닝 기법을 도입하거나 예측 label 수를 늘리기 위해 WordNet을 사용한 부분입니다. 기존의 방식으로부터 독창적인 시도를 통해 더 강력한 모델을 만들고자 한다는 점에서 해당 논문을 굉장히 흥미롭게 읽었습니다. 

## Reference
[YOLO v2 논문](https://arxiv.org/pdf/1612.08242.pdf)    
[상세하게 파고 들어 논문을 이해하는데 큰 도움이 된 블로그](https://m.blog.naver.com/sogangori/221011203855)    
[논문을 목차별로 잘 설명한 블로그](https://taeu.github.io/paper/deeplearning-paper-yolov2/)    
[Dimension Clusters에 대해 참고한 블로그](https://dhhwang89.tistory.com/136)    
